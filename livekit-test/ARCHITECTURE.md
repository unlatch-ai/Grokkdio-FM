# Architecture Overview

## Two Implementations

### 1. `podcast-agent.js` - Traditional Approach
**How it works:**
- Separate LLM API calls â†’ Get text response
- Separate TTS API calls â†’ Convert text to audio
- Sequential processing (slower)

**Use when:**
- You need fine control over LLM and TTS separately
- You want to modify text before TTS
- Testing/debugging individual components

**Run:**
```bash
npm run local
```

---

### 2. `podcast-realtime.js` - Real-time WebSocket Approach âš¡
**How it works:**
- Single WebSocket connection per agent to XAI Realtime API
- Streaming LLM + TTS combined (like phone calls)
- Audio streams as LLM generates text
- Built-in VAD (Voice Activity Detection) for interruptions
- Much faster and more natural

**Use when:**
- You want low-latency, real-time conversations
- You need interruptible agents (like phone calls)
- You want the most natural podcast flow
- **This is what you should use for your end goal!**

**Run:**
```bash
npm run realtime
```

---

## Real-time Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Podcast Orchestrator                    â”‚
â”‚  - Manages 3 agents (Alex, Sam, Jordan)                â”‚
â”‚  - Routes audio to LiveKit or Local Player              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Alex   â”‚       â”‚   Sam   â”‚       â”‚ Jordan  â”‚
   â”‚ (Agent) â”‚       â”‚ (Agent) â”‚       â”‚ (Agent) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â”‚ WebSocket       â”‚ WebSocket       â”‚ WebSocket
        â–¼                 â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚      XAI Realtime API (wss://api.x.ai)      â”‚
   â”‚  - Streaming LLM (Grok)                     â”‚
   â”‚  - Streaming TTS (Multiple voices)          â”‚
   â”‚  - Server-side VAD                          â”‚
   â”‚  - Interruption handling                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Audio Flow

### Real-time Mode:
1. **Agent.speak(prompt)** â†’ Send text via WebSocket
2. **XAI processes** â†’ LLM generates text + TTS generates audio simultaneously
3. **Audio streams back** â†’ Via WebSocket as PCM16 24kHz chunks
4. **Orchestrator routes** â†’ To LiveKit or Local Player
5. **User hears** â†’ Low-latency audio output

### Benefits:
- âš¡ **Faster**: Audio starts playing while LLM is still thinking
- ðŸŽ¯ **Natural**: Sounds like real conversation, not robotic
- ðŸ”Š **Interruptible**: VAD detects when someone else speaks
- ðŸ“ž **Phone-ready**: Same API used for Twilio integration

## LiveKit Integration

Both implementations work with `@livekit/agents`:

```javascript
export default defineAgent({
  entry: async (ctx) => {
    const podcast = new RealtimePodcastOrchestrator(topic, duration);
    await podcast.initialize(ctx.room);  // Uses LiveKit room
    await podcast.runPodcast();
  },
});
```

**Local Mode**: Preview window (what Twitch would see)
**LiveKit Mode**: Streams to LiveKit room â†’ WebRTC â†’ Multiple listeners

## Next Steps: Interruptions

To make agents truly interruptible (your end goal):

1. **Add audio input** - Capture mic or room audio
2. **Send to XAI** - Use `realtime.sendAudio(buffer)`
3. **VAD triggers** - XAI detects speech and interrupts current speaker
4. **Agent responds** - Natural back-and-forth conversation

This is already built into the XAI Realtime API! You just need to:
- Capture audio input (from LiveKit room or mic)
- Send it to the realtime WebSocket
- The API handles interruptions automatically

## Recommendation

**Use `podcast-realtime.js`** for your end goal:
- Real-time streaming
- Low latency
- Interruptible conversations
- Natural podcast flow
- Ready for Twitch/Twilio streaming
